{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d522e-cb3f-4a16-ab2d-5a1c8cbea276",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy spacy scikit-learn tensorflow datasets spacy_langdetect\n",
    "!pip install lckr_jupyterlab_variableinspector\n",
    "!pip install spacy_fastlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd459fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahil/spot/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2464e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = (pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\"))\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6e4bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train and test datasets\n",
    "predict = df['popularity']\n",
    "df = df.drop(columns=['popularity'])\n",
    "#ranged stratify split for 0 to 100\n",
    "y_binned = pd.cut(predict, bins=10, labels=False)\n",
    "df_train, df_test, df_train_pred, df_test_pred = train_test_split(df, predict, test_size=0.2, random_state=0, stratify=y_binned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4d8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop useless columns\n",
    "df_train.drop(columns=['Unnamed: 0', 'track_id'], inplace=True)\n",
    "df_test.drop(columns=['Unnamed: 0', 'track_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86480d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "#TODO FIX THIS IF BROKEN\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['explicit', 'mode',  'track_genre', 'key', 'time_signature']),\n",
    "        ('minmax_scale', MinMaxScaler(), ['duration_ms', 'loudness', 'tempo']),\n",
    "    ], remainder='passthrough') \n",
    "\n",
    "#fitting on only train prevents data leakage into test dataset \n",
    "transformer.fit(df_train)\n",
    "df_train = pd.DataFrame(transformer.transform(df_train), columns=transformer.get_feature_names_out())\n",
    "df_test = pd.DataFrame(transformer.transform(df_test), columns=transformer.get_feature_names_out())\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5dc16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import tqdm\n",
    "import torch\n",
    "#implement memory limit here\n",
    "if torch.cuda.is_available():\n",
    "    spacy.require_gpu()\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n",
    "\n",
    "def input_batch(df, batch_size):\n",
    "    results2=[]\n",
    "    texts = df['remainder_album_name'].astype(str).tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        results = []\n",
    "        for doc in nlp.pipe(batch, batch_size=batch_size, n_process=1):\n",
    "            results.append(doc._.language['language'])\n",
    "        results2.extend(results)\n",
    "    return results2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44492fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
